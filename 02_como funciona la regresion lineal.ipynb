{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# ¿Qué es la regresión lineal?\n\nTracemos un plano cartesiano en donde realizamos un gráfico de dispersión, esto es, para cada valor de $x$ le corresponde un valor en $y$, y ahora quisieramos ajustar una recta que mejor se ajuste a los datos originales (línea verde). Esta línea tiene una función de la forma:\n\n$$ y = w_0+w_1x$$\n\ndonde\n\n$w_0$: es el corte de la recta en el eje $x$ (el intercepto)\n\n$w_1$: es la pendiente\n\nEstos dos parámetros se les conoce cómo \"pesos\" puesto que son los que el modelo va a estar calculando para un mejor ajuste de la recta.\n\n- Este modelo forma parte del análisis supervisado, es decir, que se conocen los resultados que son comparados con resultados del modelo.\n\n# ¿Cuándo utilizar un modelo de regresión lineal?\n\nPara poder determinar cuándo utilizar un modelo de regresión lineal es preferible responder las siguientes preguntas:\n\n- ¿Tengo que predecir sobre una variable numérica?: peso, estatura, dinero\n- ¿Las variables independientes con las que cuento son primordialmente numéricas?\n- No cuento con una gran cantidad de variables y/o variables categóricas con muchos niveles\n\nRecomendaciones:\n- Si tienes que predecir variables numéricas empieza con regresión lineal, si no funciona, salta a otros modelos\n- Reduce las variables lo más que puedas\n- ¡Cuidado con la multicolinealidad!: cuando las variables estan muy relacionadas entre sí\n- No predigas fuera del dominio de la variable independiente\n\n# Función de pérdida y optimización: mínimo cuadrados\n\n## Pasos del algoritmo\n\nUn algoritmo de ML siempre pasa por un loop:\n\n1. Se ajusta el modelo\n2. Se comparan resultados con los reales\n3. Se ajustan pesos en el modelo: en cualquier algoritmo de ML vas a tener pesos (variables) que se van ajustando conforme vas avanzando en el modelo\n4. Regreso a paso inicial si no se converge\n\n\n",
   "metadata": {
    "cell_id": "0846d915fe7c4196a6e02cbef8401887",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 1673.21875
   }
  },
  {
   "cell_type": "markdown",
   "source": "![Picture title](image-20220422-195937.png)",
   "metadata": {
    "cell_id": "65ca6068cffc4b34bf30306fa20c702d",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 256.5625
   }
  },
  {
   "cell_type": "markdown",
   "source": "![Picture title](image-20220422-200008.png)",
   "metadata": {
    "cell_id": "1044f840aec54bc8be62ee99ae37a57e",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 260.5
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Para ejecutar este algoritmo\n\n- Función de pérdida: **método de mínimos cuadrados**. Ayuda a entender qué tan bueno es la predicción de acuerdo a los datos reales, además de que es una función que nos va a servir como guía para actualizar los parámetros de nuestros algoritmos.\n- Algoritmo de optimización: el más común es el de **descenso del gradiente**. \n\n# Evaluando el modelo: R^2 y MSE\n\n## MSE\n\n- MSE (Mean Square Error) se usa para evaluar función de pérdida\n- Es bueno revisar cuál fue este mínimo hallado por el modelo\n\n$$ MSE= \\frac{1}{N} \\displaystyle\\sum_{i=1}^{N} x_i (y_i-\\hat{y_i})^2$$\n\n- A valores grandes, peor se ajusta el modelo \n- Existen problemas de dimensionalidad\n\n## Coeficiente de determinación R^2\n\nEste coeficiente te dice qué tan bien se ajusta el modelo en base a la varianza de tus datos. Mientras más se acerque a la unidad, es mejor.\n\n$$R^2 = 1-\\frac{\\sum_{i=1}^{N}(y_i-\\hat{y_i})^2}{\\sum_{i=1}^{N}(y_i-\\bar{y_i})^2}$$\n\n## Otras métricas importantes a considerar\n\n- R - Ajustada\n- Error máximo\n- Error absoluto promedio (MAE)\n- Mediana de los errores absoluto\n- Raíz del promedio de los errores cuadrados (RMSE)\n- Varianza explicada\n\n",
   "metadata": {
    "cell_id": "13a2a2bb6cc24f65b7f3f9535bda12ef",
    "tags": [],
    "owner_user_id": "bc33c0a1-8048-44d5-b0e9-3d851b1fa595",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 1125.859375
   }
  },
  {
   "cell_type": "markdown",
   "source": "![Picture title](image-20220423-124041.png)\n\nFuente: https://www.qualtrics.com/support/stats-iq/analyses/regression-guides/interpreting-residual-plots-improve-regression/",
   "metadata": {
    "cell_id": "2be469f2afc64ecbbd65a948a8f965d5",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 376.015625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "790386b5-a859-4b7a-83fc-299325b6296b",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 66
   },
   "source": "# Start writing code here...",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8b8beb45-6e9e-4db8-96c9-28634efc9b59' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "8620553d-481c-4641-b122-7850f59ebf2b",
  "deepnote_execution_queue": []
 }
}